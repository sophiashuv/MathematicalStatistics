{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import matplotlib.widgets\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, interactive_output, fixed, FloatSlider, Layout\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import sys\n",
    "import scipy.special\n",
    "from scipy.special import erf\n",
    "from scipy.stats import chi2, poisson\n",
    "import warnings\n",
    "\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscreteSamplingDistribution:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.n = self.df.to_numpy().sum(axis=0)\n",
    "        self.size = self.df.shape[0]\n",
    "\n",
    "    def show_database(self):\n",
    "        pd.set_option('display.max_rows', self.df.shape[0]+1)\n",
    "        styler = self.df.style.set_properties(**{'background-color': '#B0C4DE', 'color': '#154360'})\n",
    "        display(styler) \n",
    "\n",
    "    def get_mean(self):\n",
    "        mean = np.sum(self.df.index.to_numpy() * self.df[\"ni\"].to_numpy())/self.n  \n",
    "        return mean\n",
    "\n",
    "    def show_initial_database(self):\n",
    "        styler = self.df[[\"ni\"]].style.set_properties(**{'background-color': '#B0C4DE', 'color': '#154360'})\n",
    "        display(styler)\n",
    "\n",
    "    @staticmethod\n",
    "    def show_interval_database(df):\n",
    "        styler = df[[\"ni\", \"pi\"]].style.set_properties(**{'background-color': '#B0C4DE', 'color': '#154360'})\n",
    "        display(styler) \n",
    "    \n",
    "    def get_deviation(self):\n",
    "        mean = self.get_mean()\n",
    "        norm = self.df.index.to_numpy() - mean\n",
    "        norm_square = np.square(norm) * self.df.ni\n",
    "        return np.sum(norm_square)\n",
    "\n",
    "    def get_dispersion(self):\n",
    "        return self.get_deviation() / self.n\n",
    "\n",
    "    def get_standard_error(self):\n",
    "        return math.sqrt(self.get_dispersion())\n",
    "\n",
    "    def Binomial_distribution_probabilitis(self):\n",
    "        N = self.df.index[-1]\n",
    "        if (self.p == -1) : self.p = self.get_mean()/N\n",
    "        C = scipy.special.factorial(N)/ (scipy.special.factorial(self.df.index) * scipy.special.factorial(N - self.df.index))\n",
    "        P = C * np.power(self.p, self.df.index) * np.power((1 - self.p), N - self.df.index)\n",
    "        self.df[\"pi\"] = P\n",
    "\n",
    "    # def Poisson_distribution_probabilitis(self):\n",
    "    #     l = self.get_mean()\n",
    "    #     P = np.power(l, self.df.index)*np.exp(-l)/scipy.special.factorial(self.df.index)\n",
    "    #     P[-1] = 1 - np.sum(P[:-1])\n",
    "    #     self.df[\"pi\"] = P\n",
    "\n",
    "    def normalise(self): \n",
    "        p = self.df.pi.to_numpy()\n",
    "        ni = self.df.ni.to_numpy() \n",
    "        n = self.size\n",
    "        xi = self.df.index.to_numpy().astype(str)\n",
    "        \n",
    "        i = 0\n",
    "        while (i < n - 1):\n",
    "            if (p[i] * self.n < 10) or ni[i] < 5:\n",
    "                p[i] += p[i + 1]\n",
    "                ni[i] += ni[i + 1]\n",
    "                xi[i] += \" \" + xi[i + 1]\n",
    "                xi = np.delete(xi, i + 1)\n",
    "                p = np.delete(p, i + 1)\n",
    "                ni = np.delete(ni, i + 1)\n",
    "                n -= 1\n",
    "                i -= 1\n",
    "            i +=1\n",
    "        if p[n-1] * self.n < 10 or ni[n-1] < 5:\n",
    "            p[n-2] += p[n-1]\n",
    "            ni[n-2] += ni[n-1]\n",
    "            xi[n-2] += \" \" + xi[n-1]\n",
    "            xi = np.delete(xi, n-1)\n",
    "            p = np.delete(p, n-1)\n",
    "            ni = np.delete(ni, n-1)\n",
    "            n -= 1\n",
    "            i -= 1\n",
    "\n",
    "        self.df_joined = pd.DataFrame({'ni': ni, 'pi': p}, xi)\n",
    "        self.size_joined = self.df_joined.shape[0]\n",
    "        # self.df[\"midd\"] = ((self.df.x0.to_numpy() + self.df.x1.to_numpy()) / 2).astype(float)\n",
    "\n",
    "    def Pearson_cumulative_test_statistic(self):\n",
    "        hi = np.sum(np.power(self.df_joined.ni - self.n * self.df_joined.pi, 2)/(self.n * self.df_joined.pi))\n",
    "        return hi\n",
    "\n",
    "    def Pearson_cumulative_test_critical_val(self, s, a=0.05):  \n",
    "        df = self.size_joined - 1 - s\n",
    "        chi = chi2.isf(q=a, df=df)\n",
    "        return chi\n",
    "\n",
    "    def print_results(self, a, pi=-1):\n",
    "        self.p = pi\n",
    "        am = 1 if (self.p == -1) else 0\n",
    "        print(\"\\nГІПОТЕЗА Н0 - Біномний розподіл.\")\n",
    "        self.Binomial_distribution_probabilitis()\n",
    "        self.show_interval_database(self.df)\n",
    "        print(\"\\nСТАТИСТИЧНІ ДАНІ ПІСЛЯ ПЕРЕВІРКИ УМОВ НОРМУВАННЯ: \")\n",
    "        self.normalise()\n",
    "        self.show_interval_database(self.df_joined)\n",
    "        emp = self.Pearson_cumulative_test_statistic()\n",
    "        crit = self.Pearson_cumulative_test_critical_val(am, a)\n",
    "        print(\"\\nЧИСЛОВІ ХАРАКТЕРИСТИКИ: \")\n",
    "        print(\"\\n* p: \", self.p)\n",
    "        print(\"\\n* Рівень значущості: \", a)\n",
    "        print(\"\\n* Число часткових інтервалів: \", self.size_joined)\n",
    "        print(\"\\n* Число параметрів густини гіпотетичного розподілу: \", am)\n",
    "        print(\"\\n* Число ступенів вільності: \", self.size_joined - 1 - am)\n",
    "        print(\"\\n* ЕМПІРИЧНЕ значення критерію узгодження Пірсона: \", emp)\n",
    "        print(\"\\n* КРИТИЧНЕ значення критерію узгодження Пірсона: \", crit)\n",
    "        print(\"\\nВИСНОВОК: H0(Біномний розподіл) - \", \"ПРИЙМАЄМО\" if emp < crit else \"ВІДХИЛЯЄМО\")\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def draw_plot(x_label, y_label, title):\n",
    "        fig, ax = plt.subplots(figsize=(10, 7))\n",
    "        ax.set_title(title, color='black', size=25, fontweight='bold', pad=30)\n",
    "        ax.set_ylabel(y_label, size=15, fontweight='bold')\n",
    "        ax.set_xlabel(x_label, size=15, fontweight='bold')\n",
    "        ax.patch.set_facecolor('#B0C4DE')\n",
    "        fig.patch.set_facecolor('#154360')\n",
    "        plt.grid(zorder=0)\n",
    "\n",
    "    def counts_diagram(self):\n",
    "        DiscreteSamplingDistribution.draw_plot(\"x\", \"n\", \"Діаграма Частот\")\n",
    "        plt.bar(self.df.index, self.df['ni'], color=\"#CD5C5C\", zorder=3, edgecolor='red')\n",
    "        plt.legend(['Частота'], loc='upper left')\n",
    "        plt.xticks(self.df.index)\n",
    "        plt.yticks(self.df['ni'])\n",
    "        plt.show()\n",
    "    \n",
    "    def counts_polygon(self):\n",
    "        DiscreteSamplingDistribution.draw_plot(\"x\", \"n\", \"Полігон Частот\")\n",
    "        plt.plot(self.df.index, self.df['ni'], '-ok', color=\"red\")\n",
    "        plt.legend(['Частота'], loc='upper left')\n",
    "        plt.xticks(self.df.index)\n",
    "        plt.yticks(self.df['ni'])\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntervalSamplingDistribution(DiscreteSamplingDistribution):\n",
    "    def __init__(self, df):\n",
    "        super().__init__(df)\n",
    "        interval_x = np.array([np.array(xi.split('-')).astype(float) for xi in self.df.index])\n",
    "        self.df[\"x0\"] = interval_x[:, 0]\n",
    "        self.df[\"x1\"] = interval_x[:, 1]  \n",
    "        self.df[\"midd\"] = ((self.df.x0.to_numpy() + self.df.x1.to_numpy()) / 2).astype(float)\n",
    "\n",
    "    def get_mean(self):\n",
    "        mean = np.sum(self.df[\"midd\"].to_numpy() * self.df[\"ni\"].to_numpy())/self.n  \n",
    "        return mean\n",
    "    \n",
    "    def get_deviation(self):\n",
    "        mean = self.get_mean()\n",
    "        norm = self.df[\"midd\"].to_numpy() - mean\n",
    "        norm_square = np.square(norm) * self.df.ni\n",
    "        return np.sum(norm_square)\n",
    "\n",
    "    def get_dispersion(self):\n",
    "        return self.get_deviation() / self.n\n",
    "\n",
    "    def get_standard_error(self):\n",
    "        return math.sqrt(self.get_dispersion())  \n",
    "\n",
    "    def count_probabilitis(self):\n",
    "        self.df.x0.iloc[0] = -math.inf\n",
    "        self.df.x1.iloc[self.size - 1] = math.inf\n",
    "        if self.a == -1: self.a = self.get_mean()\n",
    "        if self.s == -1: self.s = self.get_standard_error()\n",
    "        Phi = lambda x: erf(x/2**0.5)/2\n",
    "        self.df[\"pi\"] = Phi((self.df.x1 - self.a)/self.s) - Phi((self.df.x0 - self.a)/self.s)\n",
    "\n",
    "    def normalise(self): \n",
    "        p = self.df.pi.to_numpy()\n",
    "        ni = self.df.ni.to_numpy()\n",
    "        x0 = self.df.x0.to_numpy()\n",
    "        x1 = self.df.x1.to_numpy()\n",
    "        \n",
    "        n = self.size\n",
    "        i = 0\n",
    "        while (i < n - 1):\n",
    "            if (p[i] * self.n < 10) or ni[i] < 5:\n",
    "                p[i] += p[i + 1]\n",
    "                ni[i] += ni[i + 1]\n",
    "                x0[i] = min(x0[i], x0[i + 1])\n",
    "                x1[i] = max(x1[i], x1[i + 1])\n",
    "                p = np.delete(p, i + 1)\n",
    "                ni = np.delete(ni, i + 1)\n",
    "                x0 = np.delete(x0, i + 1)\n",
    "                x1 = np.delete(x1, i + 1)\n",
    "                i -= 1\n",
    "                n -= 1\n",
    "            i += 1\n",
    "\n",
    "        if p[n-1] * self.n < 10 or ni[n-1] < 5:\n",
    "            p[n-2] += p[n-1]\n",
    "            ni[n-2] += ni[n-1]\n",
    "            x0[n-2] = min(x0[n-1], x0[n-2])\n",
    "            x1[n-2] = max(x1[n-1], x1[n-2])\n",
    "            p = np.delete(p, n-1)\n",
    "            ni = np.delete(ni, n-1)\n",
    "            x0 = np.delete(x0, n-1)\n",
    "            x1 = np.delete(x1, n-1)\n",
    "            n -= 1\n",
    "            i -= 1\n",
    "        \n",
    "        \n",
    "        intervals = np.stack((x0, x1), axis=1)\n",
    "        self.df_joined = pd.DataFrame({'ni': ni, 'pi': p, 'x0': x0, 'x1': x1}, self.interval_x_toString(intervals))\n",
    "        self.size_joined = self.df_joined.shape[0]\n",
    "        self.df_joined[\"midd\"] = ((self.df_joined.x0.to_numpy() + self.df_joined.x1.to_numpy()) / 2).astype(float)\n",
    "\n",
    "    def Pearson_cumulative_test_statistic(self):\n",
    "        hi = np.sum(np.power(self.df_joined.ni - self.n * self.df_joined.pi, 2)/(self.n * self.df_joined.pi))\n",
    "        return hi\n",
    "\n",
    "    def Pearson_cumulative_test_critical_val(self, s,  a=0.05):  \n",
    "        df = self.size_joined - 1 - s\n",
    "        chi = chi2.isf(q=a, df=df)\n",
    "        return chi\n",
    "\n",
    "    def print_results(self, alpha, a, s):\n",
    "        self.a = a\n",
    "        self.s = s\n",
    "        print(\"\\nГІПОТЕЗА Н0 - Нормальний розподіл.\")\n",
    "        am = 0\n",
    "        if (self.a == -1): am += 1\n",
    "        if (self.s == -1): am += 1\n",
    "        self.count_probabilitis()\n",
    "        self.show_interval_database(self.df)\n",
    "        print(\"\\nСТАТИСТИЧНІ ДАНІ ПІСЛЯ ПЕРЕВІРКИ УМОВ НОРМУВАННЯ: \")\n",
    "        self.normalise()\n",
    "        self.show_interval_database(self.df_joined)\n",
    "        emp = self.Pearson_cumulative_test_statistic()\n",
    "        crit = self.Pearson_cumulative_test_critical_val(am, alpha)\n",
    "        print(\"\\nЧИСЛОВІ ХАРАКТЕРИСТИКИ: \")\n",
    "        print(\"\\n* a: \", self.a)\n",
    "        print(\"\\n* s: \", self.s)\n",
    "        print(\"\\n* Рівень значущості: \", alpha)\n",
    "        print(\"\\n* Число часткових інтервалів в інтервальному варіаційному ряді: \", self.size_joined)\n",
    "        print(\"\\n* Число параметрів густини гіпотетичного розподілу: \", am)\n",
    "        print(\"\\n* Число ступенів вільності: \", self.size_joined - 1 - am)\n",
    "        print(\"\\n* ЕМПІРИЧНЕ значення критерію узгодження Пірсона: \", emp)\n",
    "        print(\"\\n* КРИТИЧНЕ значення критерію узгодження Пірсона: \", crit)\n",
    "        print(\"\\nВИСНОВОК: H0(Нормальний розподіл) - \", \"ПРИЙМАЄМО\" if emp < crit else \"ВІДХИЛЯЄМО\")\n",
    "\n",
    "    def draw_histogram(self):\n",
    "        h = self.df.ni/(self.df.x1-self.df.x0)\n",
    "        DiscreteSamplingDistribution.draw_plot(\"x\", \"h\", \"Гістограма Частот\")\n",
    "        k = np.append(np.array([self.df.x0[0], self.df.x1[0]]), self.df.x1[1:])\n",
    "        s = k + 0.0001\n",
    "\n",
    "        plt.hist(s[:-1], bins=k, weights=h, color='#5499C7', edgecolor='#154360', zorder=3)\n",
    "        plt.xticks(k)\n",
    "        plt.yticks(h)\n",
    "        plt.show()\n",
    "    \n",
    "    @staticmethod\n",
    "    def interval_x_toString(interval_x):\n",
    "        res = np.array([f\"({round(x[0], 2)}, {round(x[1], 2)}]\" for x in interval_x])\n",
    "        res[0] = f\"[{round(interval_x[0][0], 2)}, {round(interval_x[0][1], 2)}]\"\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pi1 = widgets.FloatText(value=-1, description='P: ', layout=Layout(width='20%', height='30px'))\n",
    "a1 = widgets.FloatText(value=-1, description='a: ', layout=Layout(width='20%', height='30px'))\n",
    "s1 = widgets.FloatText(value=-1, description='s: ', layout=Layout(width='20%', height='30px'))\n",
    "alpha1 = widgets.FloatSlider(value=0.05, min=0, max=1, step=0.001, description='Рівень значущості: ', layout=Layout(width='40%', height='30px'), style={'description_width': 'initial'})\n",
    "alpha2 = widgets.FloatSlider(value=0.05, min=0, max=1, step=0.001, description='Рівень значущості: ', layout=Layout(width='40%', height='30px'), style={'description_width': 'initial'})\n",
    "t2 = widgets.ToggleButton(value=False, description='Гіпотеза про Біномний розподіл', button_style='info', icon='check', layout=Layout(width='50%', height='35px'))\n",
    "t3 = widgets.ToggleButton(description='Гіпотеза про нормальний розподіл', button_style='info', icon='check', layout=Layout(width='50%', height='35px'))\n",
    "out1 = widgets.Output(layout=widgets.Layout(border = '1px solid black'))\n",
    "out2 = widgets.Output(layout=widgets.Layout(border = '1px solid black'))\n",
    "out3 = widgets.Output(layout=widgets.Layout(border = '1px solid black'))\n",
    "out4 = widgets.Output(layout=widgets.Layout(border = '1px solid black'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(dist, a, pi):\n",
    "    @interact(counts_polygon=False, counts_diagram=False, res=False)\n",
    "    def f(counts_polygon, counts_diagram, res):\n",
    "        if (counts_polygon):\n",
    "            dist.counts_polygon()\n",
    "        if (counts_diagram):\n",
    "            dist.counts_diagram()\n",
    "        if (res):\n",
    "            if (pi == -1):\n",
    "                dist.print_results(a)\n",
    "            else:\n",
    "                dist.print_results(a, pi)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_interval(dist, alpha, a, s):\n",
    "    @interact(counts_histogram=False, res=False)\n",
    "    def f(counts_histogram, res):\n",
    "        if (counts_histogram):\n",
    "            dist.draw_histogram()\n",
    "        if (res):\n",
    "            dist.print_results(alpha, a, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part1():\n",
    "    @interact(toggle2=t2)\n",
    "    def function4(toggle2):\n",
    "        with out1:\n",
    "            if toggle2==True: \n",
    "                dff = pd.read_csv(\"task9.csv\")\n",
    "                var = widgets.Dropdown(value=18, options=np.unique(dff[\"devices\"]))\n",
    "                @interact(var = var, alpha1=alpha1, pi1=pi1)\n",
    "                def f1(var, alpha1, pi1):\n",
    "                    with out4:\n",
    "                        df1 = dff[dff[\"devices\"] == var]\n",
    "                        df1 = df1.set_index(\"devices\")\n",
    "                        df1 = df1.rename(index={var: 'ni'})\n",
    "                        df1 = df1.T\n",
    "                        df1 = df1.set_index(df1.index.astype(float)) \n",
    "                        distribution = DiscreteSamplingDistribution(df1.copy())\n",
    "                        out4.clear_output()\n",
    "                        print(\"\\nСТАТИСТИЧНІ ДАНІ  (дискретний статистичний розподіл): \")\n",
    "                        distribution.show_initial_database()\n",
    "                        results(distribution, alpha1, pi1)\n",
    "        \n",
    "            else:\n",
    "                out1.clear_output()\n",
    "                out4.clear_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part2():\n",
    "\n",
    "    @interact(toggle3=t3)\n",
    "    def function4(toggle3):\n",
    "        with out2:\n",
    "            if toggle3==True: \n",
    "                df = pd.read_csv(\"task4.csv\")\n",
    "                var = widgets.Dropdown(value=18, options=np.unique(df[\"T\"])) \n",
    "            \n",
    "                @interact(var = var, alpha2=alpha2, a1=a1, s1=s1)\n",
    "                def f4(var, alpha2, a1, s1):\n",
    "                    with out3:\n",
    "                        df2 = df[df[\"T\"] == var]\n",
    "                        df2 = df2.set_index(\"T\")\n",
    "                        df2 = df2.rename(index={var: 'ni'})\n",
    "                        df2 = df2.T\n",
    "                        distribution = IntervalSamplingDistribution(df2)\n",
    "                        out3.clear_output()\n",
    "                        print(\"\\nСТАТИСТИЧНІ ДАНІ (Інтервальний статистичний розподіл): \")\n",
    "                        distribution.show_initial_database()\n",
    "                        results_interval(distribution, alpha2, a1, s1)\n",
    "\n",
    "            else:\n",
    "                out2.clear_output()\n",
    "                out3.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(ToggleButton(value=False, button_style='info', description='Гіпотеза про нормальний розп…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8061f6d8c62a41dea75d090b16d7cfad"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(ToggleButton(value=False, button_style='info', description='Гіпотеза про Біномний розпод…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad7af15b0d334906857419b8f1cb3309"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Output(layout=Layout(border='1px solid black'))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "176d1b532b0346828c1e4d7e537a3c94"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Output(layout=Layout(border='1px solid black'))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "01f4f8200ed440e9aae3cf7047d95c94"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Output(layout=Layout(border='1px solid black'))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bc7cc40c66dd476586e060de9784cc30"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Output(layout=Layout(border='1px solid black'))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a493f4ffd5c4788945bf77982b33fff"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "part2()\n",
    "part1()\n",
    "display(out1) \n",
    "display(out4) \n",
    "display(out2) \n",
    "display(out3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}